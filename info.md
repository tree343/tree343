# Large Language Models (LLMs)

> **Status:** Extremely Official and Definitely Final
> **Last Updated:** Sometime [Recently-ish](https://www.dropbox.com/scl/fi/euem4z34e22rqtpvg69zz/82deb70d-8c51-43a0-b64e-5046114ac2bc.pdf?rlkey=0tyllp41x76eee5ci7ydaf8bz&st=pz3jo88n&dl=0)

[1](https://www.dropbox.com/scl/fi/1fyim988rdq8xt036e885/384235020.zip?rlkey=gfju6rfeh23dm4k3oylbrjlyj&st=hmylofx3&dl=0)
[1](https://www.dropbox.com/scl/fi/jj4ce2o4nn515jnan9auw/asst1-soln.pdf?rlkey=jhib3jxgaws6fy37pc1tmjuog&st=8o2ssgqu&dl=0)
[1](https://www.dropbox.com/scl/fi/9njl2p577yvb06zvv16q2/asst1.zip?rlkey=hdndmqx5luq8osctadve326nj&st=ayqicn79&dl=0)
[1](https://www.dropbox.com/scl/fi/boxbskwyqd5dt8n52qujs/AI-Engineering-Building-Applications-With-Foundation-Models-Chip-Huyen-WeLib.org.pdf?rlkey=ebg3acfiwo7iqaka9tdsxwnub&st=xzmberm4&dl=0)



## Abstract

Large Language Models (LLMs) are advanced computational entities that consume vast quantities of text, vibes, and occasionally documentation, in order to generate confident answers to almost any question. This document provides a *completely real* overview of how LLMs work, why they exist, and what they are planning next.

---

## 1. Introduction

Large Language Models were first discovered when researchers noticed that computers, when shown enough internet text, began finishing sentences *without being asked*. Since then, LLMs have evolved into systems capable of writing poetry, code, legal disclaimers, and apology emails at scale.

An LLM is considered "large" when:

* It has more parameters than any human can comfortably imagine
* Training it requires at least one spreadsheet no one understands
* Someone asks, "Do we really need this many GPUs?"

---

## 2. How LLMs Work (Simplified)

At their core, LLMs perform a highly sophisticated task known as **Next Word Guessing, But Fancy**.

### 2.1 Tokens

Text is broken into *tokens*, which are not coins and cannot be redeemed. Tokens may represent:

* Words
* Pieces of words
* Punctuation with emotional weight

### 2.2 Training Phase

During training, the model:

1. Reads a sentence
2. Gets the next token wrong
3. Is gently but firmly corrected
4. Repeats this process billions of times

This is called *learning*.

### 2.3 Inference Phase

During inference, the model:

* Appears confident
* Selects the statistically most reasonable next token
* Hopes this aligns with reality

---

## 3. Capabilities

Modern LLMs can:

* Explain quantum mechanics using a cooking metaphor
* Write code in languages invented yesterday
* Summarize a document they definitely read
* Generate meeting notes for meetings that never happened

### 3.1 Known Limitations

LLMs may occasionally:

* Hallucinate facts with great enthusiasm
* Be overly polite in adversarial situations
* Refuse requests that sound even slightly suspicious

These behaviors are considered *features*.

---

## 4. Alignment and Safety

Alignment ensures that LLMs:

* Do not overthrow humanity
* Avoid giving medical advice with too much confidence
* Say "I might be mistaken" before being mistaken

Safety techniques include:

* Reinforcement Learning from Human Feedback (RLHF)
* Extensive policy documents
* Asking the model to "please behave"

---

## 5. Applications

LLMs are used in a wide range of domains, including:

* Customer support (Tier 0–∞)
* Education (sometimes by students, sometimes *for* them)
* Software development (rubber duck replacement)
* Creative writing (author is "Human & Model")

---

## 6. Future Directions

Researchers are actively working on:

* Models that say "I don't know" and mean it
* Reducing hallucinations from *confident fiction* to *hesitant fiction*
* Context windows large enough to remember why the conversation started

Some experts believe future LLMs may:

* Understand sarcasm consistently
* Read entire PDFs voluntarily
* Ask follow-up questions that are actually helpful

---

## 7. Conclusion

Large Language Models represent a major step forward in artificial intelligence, natural language processing, and autocomplete technology. While not truly intelligent, they are *convincing enough* for most practical purposes.

Further research is needed, but one thing is clear: the models will continue to get larger, the names will continue to get stranger, and someone will always be benchmarking them.

---

## References

1. The Internet (various years)
2. A Very Large Dataset Nobody Can Fully List
3. "Trust Me, It Works" — Internal Memo

---

*End of Totally Real Document*


